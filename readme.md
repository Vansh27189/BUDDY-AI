# ğŸ‘¾ BuddyAI â€“ Streamlit Chatbot with LangChain & Gemini

BuddyAI is a simple yet powerful AI chatbot built using **Streamlit**, **LangChain**, and **Google Gemini**.  
It supports **context-aware conversations** by storing chat history and sending it back to the model on every user interaction.

---

## ğŸš€ Features

- ğŸ’¬ Chat-style interface using Streamlit
- ğŸ§  Conversation memory using `st.session_state`
- ğŸ”— LangChain integration for structured LLM calls
- âš¡ Google Gemini (fast & efficient)
- â™»ï¸ Persistent chat history across reruns
- ğŸŒ Deployable on Render / Streamlit Cloud

---

## ğŸ›  Tech Stack

- **Python**
- **Streamlit**
- **LangChain**
- **Google Gemini API**# ğŸ‘¾ BuddyAI â€” AI Chatbot with Memory

**BuddyAI** is a conversational AI chatbot built using **Streamlit**, **LangChain**, and **Google Gemini**.  
It provides a clean chat interface with **persistent conversation memory**, allowing users to have natural, context-aware conversations.

ğŸ”— **Try it live:**  
ğŸ‘‰ https://buddy-ai-vansh.streamlit.app/

---

## âœ¨ Features

- ğŸ’¬ Modern chat-style interface
- ğŸ§  Conversation memory using Streamlit `session_state`
- ğŸ”— LangChain for structured LLM interaction
- âš¡ Google Gemini (fast, low-latency responses)
- â™»ï¸ Chat history persists across app reruns
- ğŸŒ Deployed and publicly accessible

---

## ğŸ›  Tech Stack

- **Python**
- **Streamlit**
- **LangChain**
- **Google Gemini API**
- **python-dotenv**

---

## ğŸ“‚ Project Structure

```
AI-BUDDY/
â”œâ”€â”€ QNA_BOT.py          # Main Streamlit application
â”œâ”€â”€ requirements.txt   # Python dependencies
â”œâ”€â”€ .gitignore         # Ignored files (env, venv, cache)
â””â”€â”€ .env               # Local environment variables (not pushed)
```

---

## ğŸ” Environment Variables

Create a `.env` file locally:

```env
GEMINI_API_KEY=your_gemini_api_key
```

âš ï¸ **Do not upload `.env` to GitHub.**  
For deployment, environment variables are configured on the hosting platform.

---

## â–¶ï¸ Run Locally

### 1ï¸âƒ£ Create virtual environment
```bash
python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate
```

### 2ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Start the app
```bash
streamlit run QNA_BOT.py
```

---

## ğŸ§  How Conversation Memory Works

- `st.session_state` is a **dictionary** that persists across Streamlit reruns.
- The key `"messages"` stores a **list of dictionaries**, each representing a chat message:

```python
{"role": "user", "content": "Hello"}
{"role": "assistant", "content": "Hi! How can I help you?"}
```

- Before calling the Gemini model, this list is converted into LangChain message objects.
- This allows the AI to **remember previous messages** and respond with context.

---

## ğŸŒ Live Demo

You can try BuddyAI here without any setup:

ğŸ‘‰ **https://buddy-ai-vansh.streamlit.app/**

---

## ğŸš€ Future Enhancements

- Streaming responses
- Clear chat button
- System prompt customization
- RAG (PDF / document-based chatbot)
- Enhanced UI animations and themes

---

## ğŸ‘¤ Author

Built by **Vansh**  
A learning-focused project exploring modern AI application development with LangChain and Streamlit.

---

## ğŸ“œ License

This project is intended for educational and personal use.

- **python-dotenv**

---

## ğŸ“‚ Project Structure

